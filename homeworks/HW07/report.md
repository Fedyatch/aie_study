# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (1200, 9)
- Признаки: все числовые (float64)
- Пропуски: нет
- "Подлости" датасета: датасета: признаки в сильно разных шкалах (например, `f02` от -92 до +112, `f03` от -1.6 до +0.5), что делает масштабирование критически важным.

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4)
- Признаки: все числовые (float64)
- Пропуски: нет
- "Подлости" датасета: нелинейная структура кластеров + выбросы + один шумовой признак (z_noise0), что затрудняет работу KMeans.

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15000, 5)
- Признаки: все числовые (float64)
- Пропуски: нет
- "Подлости" датасета: кластеры разной плотности + фоновый шум (`f_noise`), что делает DBSCAN предпочтительным по сравнению с KMeans.

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: для всех датасетов применялся StandardScaler (масштабирование). Пропусков и категориальных признаков не было — дополнительная обработка не требовалась.
- Поиск гиперпараметров:
  - KMeans: k ∈ [2, 20], фиксировал random_state=42, n_init=10; выбирали по максимуму silhouette_score.
  - DBSCAN: eps ∈ [0.3, 2.0] с шагом 0.1, min_samples = max(5, int(0.01 * n)); выбирал по балансу между silhouette и разумной долей шума.
- Метрики: рассчитывали silhouette_score, davies_bouldin_score, calinski_harabasz_score. Для DBSCAN метрики считались только на non-noise точках (labels != -1).
- Визуализация: использовал PCA(2D) с раскраской по кластерам. t-SNE не применялся.

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):
- Dataset A (S07-hw-dataset-01.csv)
  - KMeans:
    - Подбор: k ∈ [2, 20]. 
    - Фиксировано: random_state=42, n_init=10
  - DBSCAN 
    - Подбор: eps ∈ [0.3, 2.0] с шагом ~0.1, min_samples = max(5, int(0.01 * n))
    - Учитывалась доля шума (label == -1)

- Dataset B (S07-hw-dataset-02.csv)
  - KMeans:
    - Подбор: k ∈ [2, 20]. 
    - Фиксировано: random_state=42, n_init=10
  - DBSCAN 
    - Подбор: eps ∈ [0.3, 2.0] с шагом ~0.1, min_samples = max(5, int(0.01 * n))
    - Анализ доли шума и метрик только на non-noise точках

Dataset C (S07-hw-dataset-02.csv)
  - KMeans:
    - Подбор: k ∈ [2, 20]. 
    - Фиксировано: random_state=42, n_init=10
  - DBSCAN 
    - Подбор: eps ∈ [0.3, 2.0] с шагом ~0.1, min_samples = max(5, int(0.01 * n))
    - Особое внимание — кластерам разной плотности и шуму


## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans, k=5
- Метрики (silhouette / DB / CH): Silhouette = 0.52,
Davies-Bouldin = 0.69 , Calinski-Harabasz = 11786
- Если был DBSCAN: DBSCAN дал более низкий silhouette (0.5389), но при этом пометил ~70% точек как шум — это указывает на неоптимальные параметры или неподходящую структуру для DBSCAN.
- Коротко:  KMeans показал высокий Calinski-Harabasz — это означает, что кластеры хорошо разделены и компактны. Низкий Davies-Bouldin подтверждает, что кластеры внутри себя плотные, а между собой удалённые. Отсутствие шума также говорит о том, что все точки логично распределены по двум группам

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN, eps=0.8, min_samples=5
- Метрики (silhouette / DB / CH): Silhouette = 0.2133
Davies-Bouldin = 1.0248, Calinski-Harabasz = 1916.02
- Если был DBSCAN: Доля шума: ~49%.  DBSCAN выделил 3 кластера + значительную долю шума.
- Коротко:  Несмотря на более низкий silhouette у DBSCAN, он лучше отражает реальную структуру данных: наличие шума и несферических кластеров. Высокая доля шума (почти 50%) может быть объяснена выбросами или сложной топологией данных, что характерно для DBSCAN. KMeans, напротив, принудительно распределяет все точки, что может быть неадекватным.

### 4.3 Dataset C

- Лучший метод и параметры: DBSCAN, eps=1.0, min_samples=5
- Метрики (silhouette / DB / CH): Silhouette = 0.4727
Davies-Bouldin = 0.7324, Calinski-Harabasz = 4978.63
- Если был DBSCAN: ~68%. DBSCAN выделил 4 кластера + значительную долю шума.
- Коротко:  DBSCAN демонстрирует лучшее качество по всем трём основным метрикам (высокий silhouette, низкий Davies-Bouldin, высокий Calinski-Harabasz). Даже при высокой доле шума (~68%), он эффективно выделяет плотные группы, что соответствует описанию датасета с разной плотностью кластеров.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans "ломается" на dataset B и C: в dataset B из-за нелинейной структуры и выбросов он вынужден разделять данные по сферическим границам, что приводит к низкому silhouette; в dataset C — из-за кластеров разной плотности, которые KMeans объединяет в один большой кластер.
- DBSCAN выигрывает там, где есть шум, выбросы или неоднородная плотность (dataset B и C). Он не предполагает форму кластеров и корректно помечает аномальные точки как шум, что делает его более гибким в реальных сценариях.
- Сильнее всего на результат повлияло масштабирование: без StandardScaler KMeans на dataset A давал silhouette < 0.1 из-за разных шкал признаков. Выбросы и плотность оказали решающее влияние на выбор между KMeans и DBSCAN.

### 5.2 Устойчивость (обязательно для одного датасета)

- Проведена проверка устойчивости KMeans на dataset A: 5 запусков с разными random_state (10, 20, 30, 40, 50) при фиксированном k=2.
- Результат: попарный Adjusted Rand Index (ARI) между всеми парами решений находился в диапазоне [0.96, 1.00], средний ARI = 0.98.
- Вывод: решение устойчиво, так как структура данных чёткая, кластеры компактны и хорошо разделены после масштабирования — KMeans каждый раз находит практически идентичное разбиение.

### 5.3 Интерпретация кластеров

- Интерпретация проводилась через анализ средних значений признаков внутри каждого кластера (на основе масштабированных данных).
  - Например, в dataset A: кластер 0 имел высокие значения f02, f04, f07, тогда как кластер 1 — низкие значения этих же признаков, что указывает на два противоположных профиля.
  - В dataset C: основной кластер (синий) соответствовал средним значениям, тогда как мелкие кластеры (зелёный, коричневый) выделялись экстремальными значениями по x1 и x2.
- Вывод: Кластеры имеют осмысленные профили — они отражают реальные паттерны в данных (например, «высокий/низкий» по группе признаков). Это подтверждает, что кластеризация не только статистически обоснована, но и интерпретируема в предметной области.

## 6. Conclusion

- Масштабирование обязательно при наличии признаков в разных шкалах — без него KMeans даёт бессмысленные результаты.
- KMeans подходит только для сферических, компактных кластеров — в остальных случаях он либо объединяет группы, либо разрезает их.
- DBSCAN эффективен при наличии шума, выбросов и неоднородной плотности, но требует аккуратного подбора eps и интерпретации доли шума.
- Нет единой "лучшей" метрики: silhouette, Davies-Bouldin и Calinski-Harabasz часто дают согласованные, но не всегда совпадающие сигналы — нужно смотреть на все вместе.
- Визуализация (PCA) — мощный инструмент для быстрой оценки качества кластеризации и выявления проблем (перекрытия, шума, формы).
- Устойчивость решения — важный, но часто игнорируемый аспект: хорошее разбиение должно быть воспроизводимым при разных seed’ах.
- Честный протокол (фиксация препроцессинга → подбор параметров → оценка → интерпретация) предотвращает переоценку качества.
- Выбор алгоритма должен основываться на структуре данных, а не на слепом следовании метрикам — иногда чуть более низкий silhouette у DBSCAN оправдан его способностью выделять шум.

