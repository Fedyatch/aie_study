# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-02.csv`
- Размер: (6000, 32)
- Целевая переменная: `target` — бинарная классификация; доли классов: ~74% класса 0, ~26% класса 1
- Признаки: все признаки числовые (float64 или int64). Есть несколько целочисленных признаков с малым числом уникальных значений (например, x_int_1, x_int_2), которые могут быть интерпретированы как категориальные-подобные.

## 2. Protocol

- Разбиение: train/test = 80%/20% (test_size=0.2), random_state=42, стратификация по y для сохранения пропорций классов.
- Подбор: гиперпараметры подбирались на обучающей выборке с помощью GridSearchCV с 5-кратной кросс-валидацией (cv=5). Оптимизировалась метрика ROC-AUC.
- Метрики:
accuracy — общая точность, но может вводить в заблуждение при дисбалансе;
F1 — гармоническое среднее precision и recall, важно для оценки качества предсказания редкого класса;
ROC-AUC — устойчивая метрика для бинарной классификации, особенно при умеренном дисбалансе и наличии шума.
Эти метрики уместны, так как dataset-02 содержит шум, перекрытие классов и нелинейные взаимодействия — AUC и F1 лучше отражают качество модели, чем accuracy.

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

- DummyClassifier  (strategy='most_frequent') — наивный baseline, всегда предсказывает самый частый класс.
- LogisticRegression — линейный baseline из S05, использовался в pipeline с StandardScaler.
- DecisionTreeClassifier — подбирались max_depth ([3, 5, 7, 10]) и min_samples_leaf ([5, 10, 20]) для контроля переобучения.
- RandomForestClassifier — подбирались max_depth ([5, 8, 12]), min_samples_leaf ([5, 10]) и max_features (['sqrt', 'log2']).
- GradientBoostingClassifier — подбирались max_depth ([3, 5]), learning_rate ([0.05, 0.1]) и subsample ([0.8, 1.0])

Опционально:

- StackingClassifier (с CV-логикой)

## 4. Results

- Таблица/список финальных метрик на test по всем моделям
Финальные метрики на test:

DummyClassifier: accuracy = 0.738, F1 = 0.000, ROC-AUC = 0.500
LogisticRegression: accuracy = 0.812, F1 = 0.561, ROC-AUC = 0.798
DecisionTreeClassifier: accuracy = 0.834, F1 = 0.652, ROC-AUC = 0.837
RandomForestClassifier: accuracy = 0.864, F1 = 0.674, ROC-AUC = 0.887
GradientBoostingClassifier: accuracy = 0.868, F1 = 0.703, ROC-AUC = 0.903
- Победитель (по ROC-AUC или по согласованному критерию) и краткое объяснение
Победитель: GradientBoostingClassifier — продемонстрировал наивысшие значения по всем трём метрикам. Это согласуется с природой dataset-02, содержащего нелинейные взаимодействия и шум, которые градиентный бустинг моделирует особенно эффективно.

## 5. Analysis

- Устойчивость: Проведено 5 прогонов с разными random_state (10, 20, 30, 40, 50). ROC-AUC для GradientBoosting колебался в диапазоне [0.895, 0.908], что говорит о хорошей устойчивости модели к разбиению данных.
- Ошибки: Confusion matrix для GradientBoosting: [[2566,   89],
 [ 385,  560]]
 Модель редко ошибается, называя класс 0 как 1 (низкий FP), но часто пропускает истинные положительные случаи (FN = 385). Это компромисс, характерный для задач с перекрытием классов.
    
- Интерпретация: Permutation importance выявила топ-5 признаков: f16, f01, f07, f08, f23. Признак f16 оказался наиболее важным — его перемешивание снижает AUC на ~0.08. Это согласуется с ожиданием, что в данных есть ключевые информативные признаки, которые ансамбли успешно используют.

## 6. Conclusion

Ансамбли (Random Forest, Gradient Boosting) значительно превосходят линейные модели и одиночные деревья на данных с нелинейностями и шумом.
Контроль сложности дерева (через max_depth, min_samples_leaf) критически важен для избежания переобучения.
ROC-AUC и F1 — более информативные метрики, чем accuracy, особенно при даже умеренном дисбалансе.
Честный ML-протокол (разделение train/test, CV только на train, один вызов test) предотвращает оптимистичную оценку качества.
Permutation importance — надёжный инструмент интерпретации, не зависящий от внутренней логики модели.
